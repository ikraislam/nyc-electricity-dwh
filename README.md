ğŸ“ Repository Structure â€” File & Dataset Descriptions
This repository contains all components of the NYC Energy Consumption ETL Pipeline, Data Warehouse, MongoDB storage, and visualization deliverables. Below is a detailed description of every file and its purpose in the project.
 
ğŸ“˜ 1. DataTransform.ipynb
This notebook performs the Extractâ€“Transformâ€“Load (ETL) process for the NYC Electric Consumption dataset.
It includes:
â€¢	API extraction from NYC Open Data (Socrata API)
â€¢	Data cleaning (date parsing, numeric conversion, handling nulls, removing duplicates)
â€¢	Schema standardization for downstream use
â€¢	Exporting raw and cleaned datasets
This is the primary data-processing notebook for the project.
 
ğŸ§¾ 2. DataWarehouse.sql
Full SQL script that:
â€¢	Creates the dimension tables (Dim_Date, Dim_Location, Dim_Vendor, Dim_Meter, etc.)
â€¢	Creates the Fact_EnergyConsumption fact table with surrogate keys
â€¢	Defines primary/foreign key relationships
â€¢	Structures the star schema used for Redshift
This file represents the logical and physical modeling of the NYC Energy Data Warehouse.
 
â˜ï¸ 3. Upload_Data_MangoDBAtlas.ipynb
Notebook used to load the cleaned dataset into MongoDB Atlas, the required cloud storage option for the assignment.
Includes:
â€¢	Connection setup (URI, credentials, server tests)
â€¢	Transformations to JSON-ready format
â€¢	Batch insertion with error handling & retry logic
This notebook validates that the dataset is successfully stored in the cloud.
 
ğŸ“¦ 4. electric_consumption_clean.csv.zip
Compressed version of the clean dataset used for:
â€¢	MongoDB insertion
â€¢	Redshift warehouse loading
â€¢	Visualizations
This cleaned dataset reflects post-ETL output.
 
ğŸ“¦ 5. electric_consumption_raw.csv.zip
Compressed raw dataset downloaded directly from NYC Open Data.
Included for versioning and reproducibility of the ETL pipeline.
 
ğŸ“— 6. nyc_electric_consumption_dictionary.csv
Auto-generated Data Dictionary containing:
â€¢	Column names
â€¢	Inferred data types
â€¢	Example sample values
â€¢	Professional descriptions
This file documents the schema used across MongoDB, Redshift, and analytics.
 
ğŸŸ¥ 7. nyc_energy_dw_redshift.sql
SQL script tailored for Amazon Redshift, including:
â€¢	Redshift-compatible DDL for all dimensions and fact tables
â€¢	SORTKEY / DISTKEY optimization for large tables
â€¢	COPY statements preparing Redshift loads from S3 (if used)
This script is used when deploying the Data Warehouse to AWS Redshift.
 
ğŸ“‚ 8. scripts/
Folder containing additional helper scripts, such as:
â€¢	Python utilities for API pulling
â€¢	Automated ETL pipeline components
â€¢	Batch insertion helpers
â€¢	Additional transformation modules
This directory supports reproducibility and modular code design.
 
ğŸ“Š Datasets Used
NYC Electric Consumption (2010â€“2025) â€“ Socrata Open Data
Used via API:
https://data.cityofnewyork.us/Housing-Development/Electric-Consumption-And-Cost-2010-May-2025-/jr24-e7cr
The dataset includes:
â€¢	Development name & borough
â€¢	Meter & vendor details
â€¢	Consumption (kWh / kW)
â€¢	Billing period dates
â€¢	Charges & cost data
This dataset powers:
â€¢	MongoDB storage
â€¢	The AWS Redshift Data Warehouse
â€¢	All visualizations

